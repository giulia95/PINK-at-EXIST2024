# -- modalities related
modalities:
 - name: clip_caption
   input_dim: 512

 - name: clip_image
   input_dim: 512

 - name: clip_text
   input_dim: 512

 - name: bert_caption
   input_dim: 768

 - name: bert_text
   input_dim: 768

use_modalities: [clip_caption, clip_image, clip_text, bert_caption, bert_text]

# -- languages related
languages:
 - en
 - es

# -- model architecture related
model: pink_transformer
model_conf:
  latent_dim: 256
  n_head: 8
  num_encoder_layers: 1
  dim_feedforward: 2048
  dropout: 0.1
  use_modality_emb: true
  use_language_emb: true
  modality_masking_prob: 0.8

# -- training settings related
training_settings:
  optimizer: 'adamw'
  scheduler: 'onecycle'
  anneal_strategy: 'linear'
  loss_criterion: 'cross_entropy'
  epochs: 5
  batch_size: 16
  learning_rate: 0.0002
  num_workers: 6

# -- task related
num_classes: 2
class_names:
 - sexism
 - no-sexism
report_class: 'sexism'
task: 'hard_label_task4'
language_filter: both
device: 'cuda'
seed: 42
